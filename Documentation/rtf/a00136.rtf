{\rtf1\ansi\ansicpg1252\uc1 \deff0\deflang1033\deflangfe1033
{\fonttbl {\f0\froman\fcharset0\fprq2{\*\panose 02020603050405020304}Times New Roman;}
{\f1\fswiss\fcharset0\fprq2{\*\panose 020b0604020202020204}Arial;}
{\f2\fmodern\fcharset0\fprq1{\*\panose 02070309020205020404}Courier New;}
{\f3\froman\fcharset2\fprq2{\*\panose 05050102010706020507}Symbol;}
}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;\red0\green128\blue0;\red96\green64\blue32;\rede0\green128\blue0;\red128\green0\blue0;\red128\green96\blue32;\red0\green32\blue128;\red0\green128\blue128;\red255\green0\blue255;\red0\green0\blue0;\red112\green0\blue112;\red255\green0\blue0;}
{\stylesheet
{\widctlpar\adjustright \fs20\cgrid \snext0 Normal;}
{\paperw11900\paperh16840\margl1800\margr1800\margt1440\margb1440\gutter0\ltrsect}
{\s1\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs36\kerning36\cgrid \sbasedon0 \snext0 heading 1;}
{\s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid \sbasedon0 \snext0 heading 2;}
{\s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid \sbasedon0 \snext0 heading 3;}
{\s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 4;}{\*\cs10 \additive Default Paragraph Font;}
{\s5\sb90\sa30\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext0 heading 5;}{\*\cs10 \additive Default Paragraph Font;}
{\s15\qc\sb240\sa60\widctlpar\outlinelevel0\adjustright \b\f1\fs32\kerning28\cgrid \sbasedon0 \snext15 Title;}
{\s16\qc\sa60\widctlpar\outlinelevel1\adjustright \f1\cgrid \sbasedon0 \snext16 Subtitle;}
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid \sbasedon0 \snext17 BodyText;}
{\s18\widctlpar\fs22\cgrid \sbasedon0 \snext18 DenseText;}
{\s28\widctlpar\tqc\tx4320\tqr\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext28 header;}
{\s29\widctlpar\tqc\tx4320\tqr\tx8640\qr\adjustright \fs20\cgrid \sbasedon0 \snext29 footer;}
{\s30\li360\sa60\sb120\keepn\widctlpar\adjustright \b\f1\fs20\cgrid \sbasedon0 \snext30 GroupHeader;}
{\s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext41 Code Example 0;}
{\s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext42 Code Example 1;}
{\s42\li720\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext43 Code Example 2;}
{\s43\li1080\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext44 Code Example 3;}
{\s44\li1440\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext45 Code Example 4;}
{\s45\li1800\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext46 Code Example 5;}
{\s46\li2160\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext47 Code Example 6;}
{\s47\li2520\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext48 Code Example 7;}
{\s48\li2880\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext49 Code Example 8;}
{\s49\li3240\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext50 Code Example 9;}
{\s50\li3600\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext51 Code Example 10;}
{\s51\li3960\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext52 Code Example 11;}
{\s52\li4320\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 12;}
{\s53\li4680\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid \sbasedon0 \snext53 Code Example 13;}
{\s60\li0\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext61 List Continue 0;}
{\s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext62 List Continue 1;}
{\s62\li720\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext63 List Continue 2;}
{\s63\li1080\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext64 List Continue 3;}
{\s64\li1440\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext65 List Continue 4;}
{\s65\li1800\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext66 List Continue 5;}
{\s66\li2160\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext67 List Continue 6;}
{\s67\li2520\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext68 List Continue 7;}
{\s68\li2880\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext69 List Continue 8;}
{\s69\li3240\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext70 List Continue 9;}
{\s70\li3600\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext71 List Continue 10;}
{\s71\li3960\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext72 List Continue 11;}
{\s72\li4320\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 12;}
{\s73\li4680\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid \sbasedon0 \snext73 List Continue 13;}
{\s80\li0\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext81 DescContinue 0;}
{\s81\li360\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext82 DescContinue 1;}
{\s82\li720\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext83 DescContinue 2;}
{\s83\li1080\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext84 DescContinue 3;}
{\s84\li1440\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext85 DescContinue 4;}
{\s85\li1800\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext86 DescContinue 5;}
{\s86\li2160\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext87 DescContinue 6;}
{\s87\li2520\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext88 DescContinue 7;}
{\s88\li2880\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext89 DescContinue 8;}
{\s89\li3240\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext90 DescContinue 9;}
{\s90\li3600\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext91 DescContinue 10;}
{\s91\li3960\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext92 DescContinue 11;}
{\s92\li4320\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 12;}
{\s93\li4680\widctlpar\ql\adjustright \fs20\cgrid \sbasedon0 \snext93 DescContinue 13;}
{\s100\li0\sa30\sb30\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext101 LatexTOC 0;}
{\s101\li360\sa27\sb27\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext102 LatexTOC 1;}
{\s102\li720\sa24\sb24\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext103 LatexTOC 2;}
{\s103\li1080\sa21\sb21\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext104 LatexTOC 3;}
{\s104\li1440\sa18\sb18\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext105 LatexTOC 4;}
{\s105\li1800\sa15\sb15\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext106 LatexTOC 5;}
{\s106\li2160\sa12\sb12\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext107 LatexTOC 6;}
{\s107\li2520\sa9\sb9\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext108 LatexTOC 7;}
{\s108\li2880\sa6\sb6\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext109 LatexTOC 8;}
{\s109\li3240\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext110 LatexTOC 9;}
{\s110\li3600\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext111 LatexTOC 10;}
{\s111\li3960\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext112 LatexTOC 11;}
{\s112\li4320\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 12;}
{\s113\li4680\sa3\sb3\widctlpar\tqr\tldot\tx8640\adjustright \fs20\cgrid \sbasedon0 \snext113 LatexTOC 13;}
{\s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext121 \sautoupd List Bullet 0;}
{\s121\fi-360\li720\widctlpar\jclisttab\tx720{\*\pn \pnlvlbody\ilvl0\ls2\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext122 \sautoupd List Bullet 1;}
{\s122\fi-360\li1080\widctlpar\jclisttab\tx1080{\*\pn \pnlvlbody\ilvl0\ls3\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext123 \sautoupd List Bullet 2;}
{\s123\fi-360\li1440\widctlpar\jclisttab\tx1440{\*\pn \pnlvlbody\ilvl0\ls4\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext124 \sautoupd List Bullet 3;}
{\s124\fi-360\li1800\widctlpar\jclisttab\tx1800{\*\pn \pnlvlbody\ilvl0\ls5\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext125 \sautoupd List Bullet 4;}
{\s125\fi-360\li2160\widctlpar\jclisttab\tx2160{\*\pn \pnlvlbody\ilvl0\ls6\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext126 \sautoupd List Bullet 5;}
{\s126\fi-360\li2520\widctlpar\jclisttab\tx2520{\*\pn \pnlvlbody\ilvl0\ls7\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext127 \sautoupd List Bullet 6;}
{\s127\fi-360\li2880\widctlpar\jclisttab\tx2880{\*\pn \pnlvlbody\ilvl0\ls8\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext128 \sautoupd List Bullet 7;}
{\s128\fi-360\li3240\widctlpar\jclisttab\tx3240{\*\pn \pnlvlbody\ilvl0\ls9\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext129 \sautoupd List Bullet 8;}
{\s129\fi-360\li3600\widctlpar\jclisttab\tx3600{\*\pn \pnlvlbody\ilvl0\ls10\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext130 \sautoupd List Bullet 9;}
{\s130\fi-360\li3960\widctlpar\jclisttab\tx3960{\*\pn \pnlvlbody\ilvl0\ls11\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext131 \sautoupd List Bullet 10;}
{\s131\fi-360\li4320\widctlpar\jclisttab\tx4320{\*\pn \pnlvlbody\ilvl0\ls12\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext132 \sautoupd List Bullet 11;}
{\s132\fi-360\li4680\widctlpar\jclisttab\tx4680{\*\pn \pnlvlbody\ilvl0\ls13\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 12;}
{\s133\fi-360\li5040\widctlpar\jclisttab\tx5040{\*\pn \pnlvlbody\ilvl0\ls14\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid \sbasedon0 \snext133 \sautoupd List Bullet 13;}
{\s140\fi-360\li360\widctlpar\fs20\cgrid \sbasedon0 \snext141 \sautoupd List Enum 0;}
{\s141\fi-360\li720\widctlpar\fs20\cgrid \sbasedon0 \snext142 \sautoupd List Enum 1;}
{\s142\fi-360\li1080\widctlpar\fs20\cgrid \sbasedon0 \snext143 \sautoupd List Enum 2;}
{\s143\fi-360\li1440\widctlpar\fs20\cgrid \sbasedon0 \snext144 \sautoupd List Enum 3;}
{\s144\fi-360\li1800\widctlpar\fs20\cgrid \sbasedon0 \snext145 \sautoupd List Enum 4;}
{\s145\fi-360\li2160\widctlpar\fs20\cgrid \sbasedon0 \snext146 \sautoupd List Enum 5;}
{\s146\fi-360\li2520\widctlpar\fs20\cgrid \sbasedon0 \snext147 \sautoupd List Enum 6;}
{\s147\fi-360\li2880\widctlpar\fs20\cgrid \sbasedon0 \snext148 \sautoupd List Enum 7;}
{\s148\fi-360\li3240\widctlpar\fs20\cgrid \sbasedon0 \snext149 \sautoupd List Enum 8;}
{\s149\fi-360\li3600\widctlpar\fs20\cgrid \sbasedon0 \snext150 \sautoupd List Enum 9;}
{\s150\fi-360\li3960\widctlpar\fs20\cgrid \sbasedon0 \snext151 \sautoupd List Enum 10;}
{\s151\fi-360\li4320\widctlpar\fs20\cgrid \sbasedon0 \snext152 \sautoupd List Enum 11;}
{\s152\fi-360\li4680\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 12;}
{\s153\fi-360\li5040\widctlpar\fs20\cgrid \sbasedon0 \snext153 \sautoupd List Enum 13;}
}
{\comment begin body}
\pard\plain \s2\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs28\kerning28\cgrid 
PeopleTracker.src.utils Namespace Reference\par \pard\plain 
{\tc\tcl2 \v PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils}
{\bkmkstart AAAAAAAAWK}
{\bkmkend AAAAAAAAWK}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Classes\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
class {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWL" }{}}{\fldrslt {\cs37\ul\cf2 Dataset}}}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Dataset. }}\par}
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Functions\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWM" }{}}{\fldrslt {\cs37\ul\cf2 extract_bboxes}}}
 (mask)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Bounding Boxes. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWN" }{}}{\fldrslt {\cs37\ul\cf2 compute_iou}}}
 (box1, box2)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWO" }{}}{\fldrslt {\cs37\ul\cf2 compute_overlaps_masks}}}
 (masks1, masks2)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWP" }{}}{\fldrslt {\cs37\ul\cf2 non_max_suppression}}}
 (boxes, scores, threshold)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWQ" }{}}{\fldrslt {\cs37\ul\cf2 apply_box_deltas}}}
 (boxes, deltas)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWR" }{}}{\fldrslt {\cs37\ul\cf2 box_refinement_graph}}}
 (box, gt_box)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWS" }{}}{\fldrslt {\cs37\ul\cf2 box_refinement}}}
 (box, gt_box)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWT" }{}}{\fldrslt {\cs37\ul\cf2 resize_image}}}
 (image, min_dim=None, max_dim=None, min_scale=None, mode="square")\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWU" }{}}{\fldrslt {\cs37\ul\cf2 resize_mask}}}
 (mask, scale, padding, crop=None)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWV" }{}}{\fldrslt {\cs37\ul\cf2 minimize_mask}}}
 (bbox, mask, mini_shape)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWW" }{}}{\fldrslt {\cs37\ul\cf2 expand_mask}}}
 (bbox, mini_mask, image_shape)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWX" }{}}{\fldrslt {\cs37\ul\cf2 mold_mask}}}
 (mask, config)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWY" }{}}{\fldrslt {\cs37\ul\cf2 unmold_mask}}}
 (mask, bbox, image_shape)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWZ" }{}}{\fldrslt {\cs37\ul\cf2 generate_anchors}}}
 (scales, ratios, shape, feature_stride, anchor_stride)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Anchors. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXA" }{}}{\fldrslt {\cs37\ul\cf2 generate_pyramid_anchors}}}
 (scales, ratios, feature_shapes, feature_strides, anchor_stride)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXB" }{}}{\fldrslt {\cs37\ul\cf2 trim_zeros}}}
 (x)\par
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid {\i {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Miscellaneous. }{
}\par
}\par}
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXC" }{}}{\fldrslt {\cs37\ul\cf2 compute_matches}}}
 (gt_boxes, gt_class_ids, gt_masks, pred_boxes, pred_class_ids, pred_scores, pred_masks, iou_threshold=0.5, score_threshold=0.0)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXD" }{}}{\fldrslt {\cs37\ul\cf2 compute_ap}}}
 (gt_boxes, gt_class_ids, gt_masks, pred_boxes, pred_class_ids, pred_scores, pred_masks, iou_threshold=0.5)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXE" }{}}{\fldrslt {\cs37\ul\cf2 compute_ap_range}}}
 (gt_box, gt_class_id, gt_mask, pred_box, pred_class_id, pred_score, pred_mask, iou_thresholds=None, verbose=1)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXF" }{}}{\fldrslt {\cs37\ul\cf2 compute_recall}}}
 (pred_boxes, gt_boxes, iou)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXG" }{}}{\fldrslt {\cs37\ul\cf2 batch_slice}}}
 (inputs, graph_fn, batch_size, names=None)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXH" }{}}{\fldrslt {\cs37\ul\cf2 download_trained_weights}}}
 (coco_model_path, verbose=1)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXI" }{}}{\fldrslt {\cs37\ul\cf2 norm_boxes}}}
 (boxes, shape)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXJ" }{}}{\fldrslt {\cs37\ul\cf2 denorm_boxes}}}
 (boxes, shape)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXK" }{}}{\fldrslt {\cs37\ul\cf2 resize}}}
 (image, output_shape, order=1, mode='constant', cval=0, clip=True, preserve_range=False, anti_aliasing=False, anti_aliasing_sigma=None)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXL" }{}}{\fldrslt {\cs37\ul\cf2 distance_2d}}}
 (p1, p2)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXM" }{}}{\fldrslt {\cs37\ul\cf2 get_centroid}}}
 (box)\par
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 
{\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXN" }{}}{\fldrslt {\cs37\ul\cf2 get_corners}}}
 (box)\par
}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Variables\par
\pard\plain 

{
\pard\plain \s120\fi-360\li360\widctlpar\jclisttab\tx360{\*\pn \pnlvlbody\ilvl0\ls1\pnrnot0\pndec }\ls1\adjustright \fs20\cgrid 

str {\b COCO_MODEL_URL} = "https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"{\bkmkstart AAAAAAAAXO}
{\bkmkend AAAAAAAAXO}
\par
}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Detailed Description\par
\pard\plain 
{
\pard\plain \s17\sa60\sb30\widctlpar\qj \fs22\cgrid {\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s40\li0\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Mask R-CNN\par
Common utility functions and classes.\par
\par
Copyright (c) 2017 Matterport, Inc.\par
Licensed under the MIT License (see LICENSE for details)\par
Written by Waleed Abdulla\par
}
 \par
}}
{\pard\widctlpar\brdrb\brdrs\brdrw5\brsp20 \adjustright \par}
\pard\plain \s3\sb240\sa60\keepn\widctlpar\adjustright \b\f1\cgrid 
Function Documentation\par
\pard\plain 
{\xe \v apply_box_deltas\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:apply_box_deltas}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
apply_box_deltas (  {\i boxes},   {\i deltas})}}
\par
{\bkmkstart AAAAAAAAWQ}
{\bkmkend AAAAAAAAWQ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Applies the given deltas to the given boxes.\par
boxes: [N, (y1, x1, y2, x2)]. Note that (y2, x2) is outside the box.\par
deltas: [N, (dy, dx, log(dh), log(dw))]\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 164 {\cf17 def }apply_box_deltas(boxes, deltas):\par
165     {\cf22 """Applies the given deltas to the given boxes.}\par
166 {\cf22     boxes: [N, (y1, x1, y2, x2)]. Note that (y2, x2) is outside the box.}\par
167 {\cf22     deltas: [N, (dy, dx, log(dh), log(dw))]}\par
168 {\cf22     """}\par
169     boxes = boxes.astype(np.float32)\par
170     {\cf20 # Convert to y, x, h, w}\par
171     height = boxes[:, 2] - boxes[:, 0]\par
172     width = boxes[:, 3] - boxes[:, 1]\par
173     center_y = boxes[:, 0] + 0.5 * height\par
174     center_x = boxes[:, 1] + 0.5 * width\par
175     {\cf20 # Apply deltas}\par
176     center_y += deltas[:, 0] * height\par
177     center_x += deltas[:, 1] * width\par
178     height *= np.exp(deltas[:, 2])\par
179     width *= np.exp(deltas[:, 3])\par
180     {\cf20 # Convert back to y1, x1, y2, x2}\par
181     y1 = center_y - 0.5 * height\par
182     x1 = center_x - 0.5 * width\par
183     y2 = y1 + height\par
184     x2 = x1 + width\par
185     {\cf19 return} np.stack([y1, x1, y2, x2], axis=1)\par
186 \par
187 \par
}
}
{\xe \v batch_slice\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:batch_slice}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
batch_slice (  {\i inputs},   {\i graph_fn},   {\i batch_size},   {\i names} = {\f2 None})}}
\par
{\bkmkstart AAAAAAAAXG}
{\bkmkend AAAAAAAAXG}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Splits inputs into slices and feeds each slice to a copy of the given\par
computation graph and then combines the results. It allows you to run a\par
graph on a batch of inputs even if the graph is written to support one\par
instance only.\par
\par
inputs: list of tensors. All must have the same first dimension length\par
graph_fn: A function that returns a TF tensor that's part of a graph.\par
batch_size: number of slices to divide the data into.\par
names: If provided, assigns names to the resulting tensors.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 808 {\cf17 def }batch_slice(inputs, graph_fn, batch_size, names=None):\par
809     {\cf22 """Splits inputs into slices and feeds each slice to a copy of the given}\par
810 {\cf22     computation graph and then combines the results. It allows you to run a}\par
811 {\cf22     graph on a batch of inputs even if the graph is written to support one}\par
812 {\cf22     instance only.}\par
813 {\cf22 }\par
814 {\cf22     inputs: list of tensors. All must have the same first dimension length}\par
815 {\cf22     graph_fn: A function that returns a TF tensor that's part of a graph.}\par
816 {\cf22     batch_size: number of slices to divide the data into.}\par
817 {\cf22     names: If provided, assigns names to the resulting tensors.}\par
818 {\cf22     """}\par
819     {\cf19 if} {\cf19 not} isinstance(inputs, list):\par
820         inputs = [inputs]\par
821 \par
822     outputs = []\par
823     {\cf19 for} i {\cf19 in} range(batch_size):\par
824         inputs_slice = [x[i] {\cf19 for} x {\cf19 in} inputs]\par
825         output_slice = graph_fn(*inputs_slice)\par
826         {\cf19 if} {\cf19 not} isinstance(output_slice, (tuple, list)):\par
827             output_slice = [output_slice]\par
828         outputs.append(output_slice)\par
829     {\cf20 # Change outputs from a list of slices where each is}\par
830     {\cf20 # a list of outputs to a list of outputs and each has}\par
831     {\cf20 # a list of slices}\par
832     outputs = list(zip(*outputs))\par
833 \par
834     {\cf19 if} names {\cf19 is} {\cf18 None}:\par
835         names = [{\cf18 None}] * len(outputs)\par
836 \par
837     result = [tf.stack(o, axis=0, name=n)\par
838               {\cf19 for} o, n {\cf19 in} zip(outputs, names)]\par
839     {\cf19 if} len(result) == 1:\par
840         result = result[0]\par
841 \par
842     {\cf19 return} result\par
843 \par
844 \par
}
}
{\xe \v box_refinement\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:box_refinement}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
box_refinement (  {\i box},   {\i gt_box})}}
\par
{\bkmkstart AAAAAAAAWS}
{\bkmkend AAAAAAAAWS}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Compute refinement needed to transform box to gt_box.\par
box and gt_box are [N, (y1, x1, y2, x2)]. (y2, x2) is\par
assumed to be outside the box.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 214 {\cf17 def }box_refinement(box, gt_box):\par
215     {\cf22 """Compute refinement needed to transform box to gt_box.}\par
216 {\cf22     box and gt_box are [N, (y1, x1, y2, x2)]. (y2, x2) is}\par
217 {\cf22     assumed to be outside the box.}\par
218 {\cf22     """}\par
219     box = box.astype(np.float32)\par
220     gt_box = gt_box.astype(np.float32)\par
221 \par
222     height = box[:, 2] - box[:, 0]\par
223     width = box[:, 3] - box[:, 1]\par
224     center_y = box[:, 0] + 0.5 * height\par
225     center_x = box[:, 1] + 0.5 * width\par
226 \par
227     gt_height = gt_box[:, 2] - gt_box[:, 0]\par
228     gt_width = gt_box[:, 3] - gt_box[:, 1]\par
229     gt_center_y = gt_box[:, 0] + 0.5 * gt_height\par
230     gt_center_x = gt_box[:, 1] + 0.5 * gt_width\par
231 \par
232     dy = (gt_center_y - center_y) / height\par
233     dx = (gt_center_x - center_x) / width\par
234     dh = np.log(gt_height / height)\par
235     dw = np.log(gt_width / width)\par
236 \par
237     {\cf19 return} np.stack([dy, dx, dh, dw], axis=1)\par
238 \par
239 \par
}
}
{\xe \v box_refinement_graph\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:box_refinement_graph}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
box_refinement_graph (  {\i box},   {\i gt_box})}}
\par
{\bkmkstart AAAAAAAAWR}
{\bkmkend AAAAAAAAWR}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Compute refinement needed to transform box to gt_box.\par
box and gt_box are [N, (y1, x1, y2, x2)]\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 188 {\cf17 def }box_refinement_graph(box, gt_box):\par
189     {\cf22 """Compute refinement needed to transform box to gt_box.}\par
190 {\cf22     box and gt_box are [N, (y1, x1, y2, x2)]}\par
191 {\cf22     """}\par
192     box = tf.cast(box, tf.float32)\par
193     gt_box = tf.cast(gt_box, tf.float32)\par
194 \par
195     height = box[:, 2] - box[:, 0]\par
196     width = box[:, 3] - box[:, 1]\par
197     center_y = box[:, 0] + 0.5 * height\par
198     center_x = box[:, 1] + 0.5 * width\par
199 \par
200     gt_height = gt_box[:, 2] - gt_box[:, 0]\par
201     gt_width = gt_box[:, 3] - gt_box[:, 1]\par
202     gt_center_y = gt_box[:, 0] + 0.5 * gt_height\par
203     gt_center_x = gt_box[:, 1] + 0.5 * gt_width\par
204 \par
205     dy = (gt_center_y - center_y) / height\par
206     dx = (gt_center_x - center_x) / width\par
207     dh = tf.log(gt_height / height)\par
208     dw = tf.log(gt_width / width)\par
209 \par
210     result = tf.stack([dy, dx, dh, dw], axis=1)\par
211     {\cf19 return} result\par
212 \par
213 \par
}
}
{\xe \v compute_ap\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:compute_ap}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
compute_ap (  {\i gt_boxes},   {\i gt_class_ids},   {\i gt_masks},   {\i pred_boxes},   {\i pred_class_ids},   {\i pred_scores},   {\i pred_masks},   {\i iou_threshold} = {\f2 0.5})}}
\par
{\bkmkstart AAAAAAAAXD}
{\bkmkend AAAAAAAAXD}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Compute Average Precision at a set IoU threshold (default 0.5).\par
\par
Returns:\par
mAP: Mean Average Precision\par
precisions: List of precisions at different class score thresholds.\par
recalls: List of recall values at different class score thresholds.\par
overlaps: [pred_boxes, gt_boxes] IoU overlaps.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 722                iou_threshold=0.5):\par
723     {\cf22 """Compute Average Precision at a set IoU threshold (default 0.5).}\par
724 {\cf22 }\par
725 {\cf22     Returns:}\par
726 {\cf22     mAP: Mean Average Precision}\par
727 {\cf22     precisions: List of precisions at different class score thresholds.}\par
728 {\cf22     recalls: List of recall values at different class score thresholds.}\par
729 {\cf22     overlaps: [pred_boxes, gt_boxes] IoU overlaps.}\par
730 {\cf22     """}\par
731     {\cf20 # Get matches and overlaps}\par
732     gt_match, pred_match, overlaps = compute_matches(\par
733         gt_boxes, gt_class_ids, gt_masks,\par
734         pred_boxes, pred_class_ids, pred_scores, pred_masks,\par
735         iou_threshold)\par
736 \par
737     {\cf20 # Compute precision and recall at each prediction box step}\par
738     precisions = np.cumsum(pred_match > -1) / (np.arange(len(pred_match)) + 1)\par
739     recalls = np.cumsum(pred_match > -1).astype(np.float32) / len(gt_match)\par
740 \par
741     {\cf20 # Pad with start and end values to simplify the math}\par
742     precisions = np.concatenate([[0], precisions, [0]])\par
743     recalls = np.concatenate([[0], recalls, [1]])\par
744 \par
745     {\cf20 # Ensure precision values decrease but don't increase. This way, the}\par
746     {\cf20 # precision value at each recall threshold is the maximum it can be}\par
747     {\cf20 # for all following recall thresholds, as specified by the VOC paper.}\par
748     {\cf19 for} i {\cf19 in} range(len(precisions) - 2, -1, -1):\par
749         precisions[i] = np.maximum(precisions[i], precisions[i + 1])\par
750 \par
751     {\cf20 # Compute mean AP over recall range}\par
752     indices = np.where(recalls[:-1] != recalls[1:])[0] + 1\par
753     mAP = np.sum((recalls[indices] - recalls[indices - 1]) *\par
754                  precisions[indices])\par
755 \par
756     {\cf19 return} mAP, precisions, recalls, overlaps\par
757 \par
758 \par
}
{
\ql
References {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXC" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_matches()}}}
.}\par
{
\ql
Referenced by {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXE" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_ap_range()}}}
.}\par
}
{\xe \v compute_ap_range\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:compute_ap_range}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
compute_ap_range (  {\i gt_box},   {\i gt_class_id},   {\i gt_mask},   {\i pred_box},   {\i pred_class_id},   {\i pred_score},   {\i pred_mask},   {\i iou_thresholds} = {\f2 None},   {\i verbose} = {\f2 1})}}
\par
{\bkmkstart AAAAAAAAXE}
{\bkmkend AAAAAAAAXE}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Compute AP over a range or IoU thresholds. Default range is 0.5-0.95.}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 761                      iou_thresholds={\cf18 None}, verbose=1):\par
762     {\cf22 """Compute AP over a range or IoU thresholds. Default range is 0.5-0.95."""}\par
763     {\cf20 # Default is 0.5 to 0.95 with increments of 0.05}\par
764     iou_thresholds = iou_thresholds {\cf19 or} np.arange(0.5, 1.0, 0.05)\par
765     \par
766     {\cf20 # Compute AP over range of IoU thresholds}\par
767     AP = []\par
768     {\cf19 for} iou_threshold {\cf19 in} iou_thresholds:\par
769         ap, precisions, recalls, overlaps =\\\par
770             compute_ap(gt_box, gt_class_id, gt_mask,\par
771                         pred_box, pred_class_id, pred_score, pred_mask,\par
772                         iou_threshold=iou_threshold)\par
773         {\cf19 if} verbose:\par
774             print({\cf22 "AP @\{:.2f\}:\\t \{:.3f\}"}.format(iou_threshold, ap))\par
775         AP.append(ap)\par
776     AP = np.array(AP).mean()\par
777     {\cf19 if} verbose:\par
778         print({\cf22 "AP @\{:.2f\}-\{:.2f\}:\\t \{:.3f\}"}.format(\par
779             iou_thresholds[0], iou_thresholds[-1], AP))\par
780     {\cf19 return} AP\par
781 \par
782 \par
}
{
\ql
References {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXD" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_ap()}}}
.}\par
}
{\xe \v compute_iou\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:compute_iou}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
compute_iou (  {\i box1},   {\i box2})}}
\par
{\bkmkstart AAAAAAAAWN}
{\bkmkend AAAAAAAAWN}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Computes IOU of the two bounding boxes.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 80 {\cf17 def }compute_iou(box1, box2):\par
81     {\cf22 """}\par
82 {\cf22     Computes IOU of the two bounding boxes.}\par
83 {\cf22     """}\par
84     b1_area = ()\par
85 \par
86 {\cf20 # def compute_overlaps(boxes1, boxes2):}\par
87 {\cf20 #     """Computes IoU overlaps between two sets of boxes.}\par
88 {\cf20 #     boxes1, boxes2: [N, (y1, x1, y2, x2)].}\par
89 \par
90 {\cf20 #     For better performance, pass the largest set first and the smaller second.}\par
91 {\cf20 #     """}\par
92 {\cf20 #     # Areas of anchors and GT boxes}\par
93 {\cf20 #     area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])}\par
94 {\cf20 #     area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])}\par
95 \par
96 {\cf20 #     # Compute overlaps to generate matrix [boxes1 count, boxes2 count]}\par
97 {\cf20 #     # Each cell contains the IoU value.}\par
98 {\cf20 #     overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))}\par
99 {\cf20 #     for i in range(overlaps.shape[1]):}\par
100 {\cf20 #         box2 = boxes2[i]}\par
101 {\cf20 #         overlaps[:, i] = compute_iou(box2, boxes1, area2[i], area1)}\par
102 {\cf20 #     return overlaps}\par
103 \par
104 \par
}
{
\ql
Referenced by {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWP" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.non_max_suppression()}}}
.}\par
}
{\xe \v compute_matches\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:compute_matches}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
compute_matches (  {\i gt_boxes},   {\i gt_class_ids},   {\i gt_masks},   {\i pred_boxes},   {\i pred_class_ids},   {\i pred_scores},   {\i pred_masks},   {\i iou_threshold} = {\f2 0.5},   {\i score_threshold} = {\f2 0.0})}}
\par
{\bkmkstart AAAAAAAAXC}
{\bkmkend AAAAAAAAXC}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Finds matches between prediction and ground truth instances.\par
\par
Returns:\par
    gt_match: 1-D array. For each GT box it has the index of the matched\par
              predicted box.\par
    pred_match: 1-D array. For each predicted box, it has the index of\par
                the matched ground truth box.\par
    overlaps: [pred_boxes, gt_boxes] IoU overlaps.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 663                     iou_threshold=0.5, score_threshold=0.0):\par
664     {\cf22 """Finds matches between prediction and ground truth instances.}\par
665 {\cf22 }\par
666 {\cf22     Returns:}\par
667 {\cf22         gt_match: 1-D array. For each GT box it has the index of the matched}\par
668 {\cf22                   predicted box.}\par
669 {\cf22         pred_match: 1-D array. For each predicted box, it has the index of}\par
670 {\cf22                     the matched ground truth box.}\par
671 {\cf22         overlaps: [pred_boxes, gt_boxes] IoU overlaps.}\par
672 {\cf22     """}\par
673     {\cf20 # Trim zero padding}\par
674     {\cf20 # TODO: cleaner to do zero unpadding upstream}\par
675     gt_boxes = trim_zeros(gt_boxes)\par
676     gt_masks = gt_masks[..., :gt_boxes.shape[0]]\par
677     pred_boxes = trim_zeros(pred_boxes)\par
678     pred_scores = pred_scores[:pred_boxes.shape[0]]\par
679     {\cf20 # Sort predictions by score from high to low}\par
680     indices = np.argsort(pred_scores)[::-1]\par
681     pred_boxes = pred_boxes[indices]\par
682     pred_class_ids = pred_class_ids[indices]\par
683     pred_scores = pred_scores[indices]\par
684     pred_masks = pred_masks[..., indices]\par
685 \par
686     {\cf20 # Compute IoU overlaps [pred_masks, gt_masks]}\par
687     overlaps = compute_overlaps_masks(pred_masks, gt_masks)\par
688 \par
689     {\cf20 # Loop through predictions and find matching ground truth boxes}\par
690     match_count = 0\par
691     pred_match = -1 * np.ones([pred_boxes.shape[0]])\par
692     gt_match = -1 * np.ones([gt_boxes.shape[0]])\par
693     {\cf19 for} i {\cf19 in} range(len(pred_boxes)):\par
694         {\cf20 # Find best matching ground truth box}\par
695         {\cf20 # 1. Sort matches by score}\par
696         sorted_ixs = np.argsort(overlaps[i])[::-1]\par
697         {\cf20 # 2. Remove low scores}\par
698         low_score_idx = np.where(overlaps[i, sorted_ixs] < score_threshold)[0]\par
699         {\cf19 if} low_score_idx.size > 0:\par
700             sorted_ixs = sorted_ixs[:low_score_idx[0]]\par
701         {\cf20 # 3. Find the match}\par
702         {\cf19 for} j {\cf19 in} sorted_ixs:\par
703             {\cf20 # If ground truth box is already matched, go to next one}\par
704             {\cf19 if} gt_match[j] > -1:\par
705                 {\cf19 continue}\par
706             {\cf20 # If we reach IoU smaller than the threshold, end the loop}\par
707             iou = overlaps[i, j]\par
708             {\cf19 if} iou < iou_threshold:\par
709                 {\cf19 break}\par
710             {\cf20 # Do we have a match?}\par
711             {\cf19 if} pred_class_ids[i] == gt_class_ids[j]:\par
712                 match_count += 1\par
713                 gt_match[j] = i\par
714                 pred_match[i] = j\par
715                 {\cf19 break}\par
716 \par
717     {\cf19 return} gt_match, pred_match, overlaps\par
718 \par
719 \par
}
{
\ql
References {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWO" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_overlaps_masks()}}}
, and {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXB" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.trim_zeros()}}}
.}\par
{
\ql
Referenced by {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXD" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_ap()}}}
.}\par
}
{\xe \v compute_overlaps_masks\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:compute_overlaps_masks}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
compute_overlaps_masks (  {\i masks1},   {\i masks2})}}
\par
{\bkmkstart AAAAAAAAWO}
{\bkmkend AAAAAAAAWO}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Computes IoU overlaps between two sets of masks.\par
masks1, masks2: [Height, Width, instances]\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 105 {\cf17 def }compute_overlaps_masks(masks1, masks2):\par
106     {\cf22 """Computes IoU overlaps between two sets of masks.}\par
107 {\cf22     masks1, masks2: [Height, Width, instances]}\par
108 {\cf22     """}\par
109     \par
110     {\cf20 # If either set of masks is empty return empty result}\par
111     {\cf19 if} masks1.shape[-1] == 0 {\cf19 or} masks2.shape[-1] == 0:\par
112         {\cf19 return} np.zeros((masks1.shape[-1], masks2.shape[-1]))\par
113     {\cf20 # flatten masks and compute their areas}\par
114     masks1 = np.reshape(masks1 > .5, (-1, masks1.shape[-1])).astype(np.float32)\par
115     masks2 = np.reshape(masks2 > .5, (-1, masks2.shape[-1])).astype(np.float32)\par
116     area1 = np.sum(masks1, axis=0)\par
117     area2 = np.sum(masks2, axis=0)\par
118 \par
119     {\cf20 # intersections and union}\par
120     intersections = np.dot(masks1.T, masks2)\par
121     union = area1[:, {\cf18 None}] + area2[{\cf18 None}, :] - intersections\par
122     overlaps = intersections / union\par
123 \par
124     {\cf19 return} overlaps\par
125 \par
126 \par
}
{
\ql
Referenced by {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXC" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_matches()}}}
, and {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXF" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_recall()}}}
.}\par
}
{\xe \v compute_recall\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:compute_recall}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
compute_recall (  {\i pred_boxes},   {\i gt_boxes},   {\i iou})}}
\par
{\bkmkstart AAAAAAAAXF}
{\bkmkend AAAAAAAAXF}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Compute the recall at the given IoU threshold. It's an indication\par
of how many GT boxes were found by the given prediction boxes.\par
\par
pred_boxes: [N, (y1, x1, y2, x2)] in image coordinates\par
gt_boxes: [N, (y1, x1, y2, x2)] in image coordinates\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 783 {\cf17 def }compute_recall(pred_boxes, gt_boxes, iou):\par
784     {\cf22 """Compute the recall at the given IoU threshold. It's an indication}\par
785 {\cf22     of how many GT boxes were found by the given prediction boxes.}\par
786 {\cf22 }\par
787 {\cf22     pred_boxes: [N, (y1, x1, y2, x2)] in image coordinates}\par
788 {\cf22     gt_boxes: [N, (y1, x1, y2, x2)] in image coordinates}\par
789 {\cf22     """}\par
790     {\cf20 # Measure overlaps}\par
791     overlaps = compute_overlaps_masks(pred_boxes, gt_boxes)\par
792     iou_max = np.max(overlaps, axis=1)\par
793     iou_argmax = np.argmax(overlaps, axis=1)\par
794     positive_ids = np.where(iou_max >= iou)[0]\par
795     matched_gt_boxes = iou_argmax[positive_ids]\par
796 \par
797     recall = len(set(matched_gt_boxes)) / gt_boxes.shape[0]\par
798     {\cf19 return} recall, positive_ids\par
799 \par
800 \par
801 {\cf20 # ## Batch Slicing}\par
802 {\cf20 # Some custom layers support a batch size of 1 only, and require a lot of work}\par
803 {\cf20 # to support batches greater than 1. This function slices an input tensor}\par
804 {\cf20 # across the batch dimension and feeds batches of size 1. Effectively,}\par
805 {\cf20 # an easy way to support batches > 1 quickly with little code modification.}\par
806 {\cf20 # In the long run, it's more efficient to modify the code to support large}\par
807 {\cf20 # batches and getting rid of this function. Consider this a temporary solution}\par
}
{
\ql
References {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWO" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_overlaps_masks()}}}
.}\par
}
{\xe \v denorm_boxes\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:denorm_boxes}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
denorm_boxes (  {\i boxes},   {\i shape})}}
\par
{\bkmkstart AAAAAAAAXJ}
{\bkmkend AAAAAAAAXJ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Converts boxes from normalized coordinates to pixel coordinates.\par
boxes: [N, (y1, x1, y2, x2)] in normalized coordinates\par
shape: [..., (height, width)] in pixels\par
\par
Note: In pixel coordinates (y2, x2) is outside the box. But in normalized\par
coordinates it's inside the box.\par
\par
Returns:\par
    [N, (y1, x1, y2, x2)] in pixel coordinates\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 875 {\cf17 def }denorm_boxes(boxes, shape):\par
876     {\cf22 """Converts boxes from normalized coordinates to pixel coordinates.}\par
877 {\cf22     boxes: [N, (y1, x1, y2, x2)] in normalized coordinates}\par
878 {\cf22     shape: [..., (height, width)] in pixels}\par
879 {\cf22 }\par
880 {\cf22     Note: In pixel coordinates (y2, x2) is outside the box. But in normalized}\par
881 {\cf22     coordinates it's inside the box.}\par
882 {\cf22 }\par
883 {\cf22     Returns:}\par
884 {\cf22         [N, (y1, x1, y2, x2)] in pixel coordinates}\par
885 {\cf22     """}\par
886     h, w = shape\par
887     scale = np.array([h - 1, w - 1, h - 1, w - 1])\par
888     shift = np.array([0, 0, 1, 1])\par
889     {\cf19 return} np.around(np.multiply(boxes, scale) + shift).astype(np.int32)\par
890 \par
891 \par
}
}
{\xe \v distance_2d\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:distance_2d}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
distance_2d (  {\i p1},   {\i p2})}}
\par
{\bkmkstart AAAAAAAAXL}
{\bkmkend AAAAAAAAXL}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 915 {\cf17 def }distance_2d(p1, p2):\par
916     {\cf19 return} abs( ((p2[0]-p1[0])**2 + (p2[1]-p1[1])**2)**(1/2) )\par
917 \par
}
}
{\xe \v download_trained_weights\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:download_trained_weights}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
download_trained_weights (  {\i coco_model_path},   {\i verbose} = {\f2 1})}}
\par
{\bkmkstart AAAAAAAAXH}
{\bkmkend AAAAAAAAXH}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Download COCO trained weights from Releases.\par
\par
coco_model_path: local path of COCO trained weights\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 845 {\cf17 def }download_trained_weights(coco_model_path, verbose=1):\par
846     {\cf22 """Download COCO trained weights from Releases.}\par
847 {\cf22 }\par
848 {\cf22     coco_model_path: local path of COCO trained weights}\par
849 {\cf22     """}\par
850     {\cf19 if} verbose > 0:\par
851         print({\cf22 "Downloading pretrained model to "} + coco_model_path + {\cf22 " ..."})\par
852     {\cf17 with} urllib.request.urlopen(COCO_MODEL_URL) {\cf17 as} resp, open(coco_model_path, {\cf22 'wb'}) {\cf17 as} out:\par
853         shutil.copyfileobj(resp, out)\par
854     {\cf19 if} verbose > 0:\par
855         print({\cf22 "... done downloading pretrained model!"})\par
856 \par
857 \par
}
}
{\xe \v expand_mask\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:expand_mask}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
expand_mask (  {\i bbox},   {\i mini_mask},   {\i image_shape})}}
\par
{\bkmkstart AAAAAAAAWW}
{\bkmkend AAAAAAAAWW}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Resizes mini masks back to image size. Reverses the change\par
of minimize_mask().\par
\par
See inspect_data.ipynb notebook for more details.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 542 {\cf17 def }expand_mask(bbox, mini_mask, image_shape):\par
543     {\cf22 """Resizes mini masks back to image size. Reverses the change}\par
544 {\cf22     of minimize_mask().}\par
545 {\cf22 }\par
546 {\cf22     See inspect_data.ipynb notebook for more details.}\par
547 {\cf22     """}\par
548     mask = np.zeros(image_shape[:2] + (mini_mask.shape[-1],), dtype=bool)\par
549     {\cf19 for} i {\cf19 in} range(mask.shape[-1]):\par
550         m = mini_mask[:, :, i]\par
551         y1, x1, y2, x2 = bbox[i][:4]\par
552         h = y2 - y1\par
553         w = x2 - x1\par
554         {\cf20 # Resize with bilinear interpolation}\par
555         m = resize(m, (h, w))\par
556         mask[y1:y2, x1:x2, i] = np.around(m).astype(np.bool)\par
557     {\cf19 return} mask\par
558 \par
559 \par
560 {\cf20 # TODO: Build and use this function to reduce code duplication}\par
}
{
\ql
References {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXK" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.resize()}}}
.}\par
}
{\xe \v extract_bboxes\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:extract_bboxes}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
extract_bboxes (  {\i mask})}}
\par
{\bkmkstart AAAAAAAAWM}
{\bkmkend AAAAAAAAWM}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Bounding Boxes. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Compute bounding boxes from masks.\par
mask: [height, width, num_instances]. Mask pixels are either 1 or 0.\par
\par
Returns: bbox array [num_instances, (y1, x1, y2, x2)].\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 34 {\cf17 def }extract_bboxes(mask):\par
35     {\cf22 """Compute bounding boxes from masks.}\par
36 {\cf22     mask: [height, width, num_instances]. Mask pixels are either 1 or 0.}\par
37 {\cf22 }\par
38 {\cf22     Returns: bbox array [num_instances, (y1, x1, y2, x2)].}\par
39 {\cf22     """}\par
40     boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\par
41     {\cf19 for} i {\cf19 in} range(mask.shape[-1]):\par
42         m = mask[:, :, i]\par
43         {\cf20 # Bounding box.}\par
44         horizontal_indicies = np.where(np.any(m, axis=0))[0]\par
45         vertical_indicies = np.where(np.any(m, axis=1))[0]\par
46         {\cf19 if} horizontal_indicies.shape[0]:\par
47             x1, x2 = horizontal_indicies[[0, -1]]\par
48             y1, y2 = vertical_indicies[[0, -1]]\par
49             {\cf20 # x2 and y2 should not be part of the box. Increment by 1.}\par
50             x2 += 1\par
51             y2 += 1\par
52         {\cf19 else}:\par
53             {\cf20 # No mask for this instance. Might happen due to}\par
54             {\cf20 # resizing or cropping. Set bbox to zeros}\par
55             x1, x2, y1, y2 = 0, 0, 0, 0\par
56         boxes[i] = np.array([y1, x1, y2, x2])\par
57     {\cf19 return} boxes.astype(np.int32)\par
58 \par
59 \par
60 {\cf20 # def compute_iou(box, boxes, box_area, boxes_area):}\par
61 {\cf20 #     """Calculates IoU of the given box with the array of the given boxes.}\par
62 {\cf20 #     box: 1D vector [y1, x1, y2, x2]}\par
63 {\cf20 #     boxes: [boxes_count, (y1, x1, y2, x2)]}\par
64 {\cf20 #     box_area: float. the area of 'box'}\par
65 {\cf20 #     boxes_area: array of length boxes_count.}\par
66 \par
67 {\cf20 #     Note: the areas are passed in rather than calculated here for}\par
68 {\cf20 #     efficiency. Calculate once in the caller to avoid duplicate work.}\par
69 {\cf20 #     """}\par
70 {\cf20 #     # Calculate intersection areas}\par
71 {\cf20 #     y1 = np.maximum(box[0], boxes[:, 0])}\par
72 {\cf20 #     y2 = np.minimum(box[2], boxes[:, 2])}\par
73 {\cf20 #     x1 = np.maximum(box[1], boxes[:, 1])}\par
74 {\cf20 #     x2 = np.minimum(box[3], boxes[:, 3])}\par
75 {\cf20 #     intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)}\par
76 {\cf20 #     union = box_area + boxes_area[:] - intersection[:]}\par
77 {\cf20 #     iou = intersection / union}\par
78 {\cf20 #     return iou}\par
79 \par
}
}
{\xe \v generate_anchors\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:generate_anchors}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
generate_anchors (  {\i scales},   {\i ratios},   {\i shape},   {\i feature_stride},   {\i anchor_stride})}}
\par
{\bkmkstart AAAAAAAAWZ}
{\bkmkend AAAAAAAAWZ}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Anchors. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid scales: 1D array of anchor sizes in pixels. Example: [32, 64, 128]\par
ratios: 1D array of anchor ratios of width/height. Example: [0.5, 1, 2]\par
shape: [height, width] spatial shape of the feature map over which\par
        to generate anchors.\par
feature_stride: Stride of the feature map relative to the image in pixels.\par
anchor_stride: Stride of anchors on the feature map. For example, if the\par
    value is 2 then generate anchors for every other feature map pixel.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 588 {\cf17 def }generate_anchors(scales, ratios, shape, feature_stride, anchor_stride):\par
589     {\cf22 """}\par
590 {\cf22     scales: 1D array of anchor sizes in pixels. Example: [32, 64, 128]}\par
591 {\cf22     ratios: 1D array of anchor ratios of width/height. Example: [0.5, 1, 2]}\par
592 {\cf22     shape: [height, width] spatial shape of the feature map over which}\par
593 {\cf22             to generate anchors.}\par
594 {\cf22     feature_stride: Stride of the feature map relative to the image in pixels.}\par
595 {\cf22     anchor_stride: Stride of anchors on the feature map. For example, if the}\par
596 {\cf22         value is 2 then generate anchors for every other feature map pixel.}\par
597 {\cf22     """}\par
598     {\cf20 # Get all combinations of scales and ratios}\par
599     scales, ratios = np.meshgrid(np.array(scales), np.array(ratios))\par
600     scales = scales.flatten()\par
601     ratios = ratios.flatten()\par
602 \par
603     {\cf20 # Enumerate heights and widths from scales and ratios}\par
604     heights = scales / np.sqrt(ratios)\par
605     widths = scales * np.sqrt(ratios)\par
606 \par
607     {\cf20 # Enumerate shifts in feature space}\par
608     shifts_y = np.arange(0, shape[0], anchor_stride) * feature_stride\par
609     shifts_x = np.arange(0, shape[1], anchor_stride) * feature_stride\par
610     shifts_x, shifts_y = np.meshgrid(shifts_x, shifts_y)\par
611 \par
612     {\cf20 # Enumerate combinations of shifts, widths, and heights}\par
613     box_widths, box_centers_x = np.meshgrid(widths, shifts_x)\par
614     box_heights, box_centers_y = np.meshgrid(heights, shifts_y)\par
615 \par
616     {\cf20 # Reshape to get a list of (y, x) and a list of (h, w)}\par
617     box_centers = np.stack(\par
618         [box_centers_y, box_centers_x], axis=2).reshape([-1, 2])\par
619     box_sizes = np.stack([box_heights, box_widths], axis=2).reshape([-1, 2])\par
620 \par
621     {\cf20 # Convert to corner coordinates (y1, x1, y2, x2)}\par
622     boxes = np.concatenate([box_centers - 0.5 * box_sizes,\par
623                             box_centers + 0.5 * box_sizes], axis=1)\par
624     {\cf19 return} boxes\par
625 \par
626 \par
}
{
\ql
Referenced by {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXA" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.generate_pyramid_anchors()}}}
.}\par
}
{\xe \v generate_pyramid_anchors\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:generate_pyramid_anchors}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
generate_pyramid_anchors (  {\i scales},   {\i ratios},   {\i feature_shapes},   {\i feature_strides},   {\i anchor_stride})}}
\par
{\bkmkstart AAAAAAAAXA}
{\bkmkend AAAAAAAAXA}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Generate anchors at different levels of a feature pyramid. Each scale\par
is associated with a level of the pyramid, but each ratio is used in\par
all levels of the pyramid.\par
\par
Returns:\par
anchors: [N, (y1, x1, y2, x2)]. All generated anchors in one array. Sorted\par
    with the same order of the given scales. So, anchors of scale[0] come\par
    first, then anchors of scale[1], and so on.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 628                              anchor_stride):\par
629     {\cf22 """Generate anchors at different levels of a feature pyramid. Each scale}\par
630 {\cf22     is associated with a level of the pyramid, but each ratio is used in}\par
631 {\cf22     all levels of the pyramid.}\par
632 {\cf22 }\par
633 {\cf22     Returns:}\par
634 {\cf22     anchors: [N, (y1, x1, y2, x2)]. All generated anchors in one array. Sorted}\par
635 {\cf22         with the same order of the given scales. So, anchors of scale[0] come}\par
636 {\cf22         first, then anchors of scale[1], and so on.}\par
637 {\cf22     """}\par
638     {\cf20 # Anchors}\par
639     {\cf20 # [anchor_count, (y1, x1, y2, x2)]}\par
640     anchors = []\par
641     {\cf19 for} i {\cf19 in} range(len(scales)):\par
642         anchors.append(generate_anchors(scales[i], ratios, feature_shapes[i],\par
643                                         feature_strides[i], anchor_stride))\par
644     {\cf19 return} np.concatenate(anchors, axis=0)\par
645 \par
646 \par
}
{
\ql
References {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWZ" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.generate_anchors()}}}
.}\par
}
{\xe \v get_centroid\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:get_centroid}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
get_centroid (  {\i box})}}
\par
{\bkmkstart AAAAAAAAXM}
{\bkmkend AAAAAAAAXM}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid returns centroid of a box, given the box is in format (x1, y1, x2, y2)\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 918 {\cf17 def }get_centroid(box):\par
919     {\cf22 '''}\par
920 {\cf22     returns centroid of a box, given the box is in format (x1, y1, x2, y2)}\par
921 {\cf22     '''}\par
922     {\cf19 return} ((box[0] - box[2])/2), ((box[1] - box[3])/2)\par
923 \par
}
}
{\xe \v get_corners\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:get_corners}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
get_corners (  {\i box})}}
\par
{\bkmkstart AAAAAAAAXN}
{\bkmkend AAAAAAAAXN}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid returns 2 point pairs describing the corners of the box\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 924 {\cf17 def }get_corners(box):\par
925     {\cf22 '''}\par
926 {\cf22     returns 2 point pairs describing the corners of the box}\par
927 {\cf22     '''}\par
928     {\cf19 return} ((box[0],box[1]), (box[2],box[3]))\par
}
}
{\xe \v minimize_mask\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:minimize_mask}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
minimize_mask (  {\i bbox},   {\i mask},   {\i mini_shape})}}
\par
{\bkmkstart AAAAAAAAWV}
{\bkmkend AAAAAAAAWV}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Resize masks to a smaller version to reduce memory load.\par
Mini-masks can be resized back to image scale using expand_masks()\par
\par
See inspect_data.ipynb notebook for more details.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 522 {\cf17 def }minimize_mask(bbox, mask, mini_shape):\par
523     {\cf22 """Resize masks to a smaller version to reduce memory load.}\par
524 {\cf22     Mini-masks can be resized back to image scale using expand_masks()}\par
525 {\cf22 }\par
526 {\cf22     See inspect_data.ipynb notebook for more details.}\par
527 {\cf22     """}\par
528     mini_mask = np.zeros(mini_shape + (mask.shape[-1],), dtype=bool)\par
529     {\cf19 for} i {\cf19 in} range(mask.shape[-1]):\par
530         {\cf20 # Pick slice and cast to bool in case load_mask() returned wrong dtype}\par
531         m = mask[:, :, i].astype(bool)\par
532         y1, x1, y2, x2 = bbox[i][:4]\par
533         m = m[y1:y2, x1:x2]\par
534         {\cf19 if} m.size == 0:\par
535             {\cf19 raise} Exception({\cf22 "Invalid bounding box with area of zero"})\par
536         {\cf20 # Resize with bilinear interpolation}\par
537         m = resize(m, mini_shape)\par
538         mini_mask[:, :, i] = np.around(m).astype(np.bool)\par
539     {\cf19 return} mini_mask\par
540 \par
541 \par
}
{
\ql
References {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXK" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.resize()}}}
.}\par
}
{\xe \v mold_mask\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:mold_mask}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
mold_mask (  {\i mask},   {\i config})}}
\par
{\bkmkstart AAAAAAAAWX}
{\bkmkend AAAAAAAAWX}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 561 {\cf17 def }mold_mask(mask, config):\par
562     {\cf19 pass}\par
563 \par
564 \par
}
}
{\xe \v non_max_suppression\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:non_max_suppression}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
non_max_suppression (  {\i boxes},   {\i scores},   {\i threshold})}}
\par
{\bkmkstart AAAAAAAAWP}
{\bkmkend AAAAAAAAWP}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Performs non-maximum suppression and returns indices of kept boxes.\par
boxes: [N, (y1, x1, y2, x2)]. Notice that (y2, x2) lays outside the box.\par
scores: 1-D array of box scores.\par
threshold: Float. IoU threshold to use for filtering.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 127 {\cf17 def }non_max_suppression(boxes, scores, threshold):\par
128     {\cf22 """Performs non-maximum suppression and returns indices of kept boxes.}\par
129 {\cf22     boxes: [N, (y1, x1, y2, x2)]. Notice that (y2, x2) lays outside the box.}\par
130 {\cf22     scores: 1-D array of box scores.}\par
131 {\cf22     threshold: Float. IoU threshold to use for filtering.}\par
132 {\cf22     """}\par
133     {\cf17 assert} boxes.shape[0] > 0\par
134     {\cf19 if} boxes.dtype.kind != {\cf22 "f"}:\par
135         boxes = boxes.astype(np.float32)\par
136 \par
137     {\cf20 # Compute box areas}\par
138     y1 = boxes[:, 0]\par
139     x1 = boxes[:, 1]\par
140     y2 = boxes[:, 2]\par
141     x2 = boxes[:, 3]\par
142     area = (y2 - y1) * (x2 - x1)\par
143 \par
144     {\cf20 # Get indicies of boxes sorted by scores (highest first)}\par
145     ixs = scores.argsort()[::-1]\par
146 \par
147     pick = []\par
148     {\cf19 while} len(ixs) > 0:\par
149         {\cf20 # Pick top box and add its index to the list}\par
150         i = ixs[0]\par
151         pick.append(i)\par
152         {\cf20 # Compute IoU of the picked box with the rest}\par
153         iou = compute_iou(boxes[i], boxes[ixs[1:]], area[i], area[ixs[1:]])\par
154         {\cf20 # Identify boxes with IoU over the threshold. This}\par
155         {\cf20 # returns indices into ixs[1:], so add 1 to get}\par
156         {\cf20 # indices into ixs.}\par
157         remove_ixs = np.where(iou > threshold)[0] + 1\par
158         {\cf20 # Remove indices of the picked and overlapped boxes.}\par
159         ixs = np.delete(ixs, remove_ixs)\par
160         ixs = np.delete(ixs, 0)\par
161     {\cf19 return} np.array(pick, dtype=np.int32)\par
162 \par
163 \par
}
{
\ql
References {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWN" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_iou()}}}
.}\par
}
{\xe \v norm_boxes\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:norm_boxes}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
norm_boxes (  {\i boxes},   {\i shape})}}
\par
{\bkmkstart AAAAAAAAXI}
{\bkmkend AAAAAAAAXI}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Converts boxes from pixel coordinates to normalized coordinates.\par
boxes: [N, (y1, x1, y2, x2)] in pixel coordinates\par
shape: [..., (height, width)] in pixels\par
\par
Note: In pixel coordinates (y2, x2) is outside the box. But in normalized\par
coordinates it's inside the box.\par
\par
Returns:\par
    [N, (y1, x1, y2, x2)] in normalized coordinates\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 858 {\cf17 def }norm_boxes(boxes, shape):\par
859     {\cf22 """Converts boxes from pixel coordinates to normalized coordinates.}\par
860 {\cf22     boxes: [N, (y1, x1, y2, x2)] in pixel coordinates}\par
861 {\cf22     shape: [..., (height, width)] in pixels}\par
862 {\cf22 }\par
863 {\cf22     Note: In pixel coordinates (y2, x2) is outside the box. But in normalized}\par
864 {\cf22     coordinates it's inside the box.}\par
865 {\cf22 }\par
866 {\cf22     Returns:}\par
867 {\cf22         [N, (y1, x1, y2, x2)] in normalized coordinates}\par
868 {\cf22     """}\par
869     h, w = shape\par
870     scale = np.array([h - 1, w - 1, h - 1, w - 1])\par
871     shift = np.array([0, 0, 1, 1])\par
872     {\cf19 return} np.divide((boxes - shift), scale).astype(np.float32)\par
873 \par
874 \par
}
}
{\xe \v resize\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:resize}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
resize (  {\i image},   {\i output_shape},   {\i order} = {\f2 1},   {\i mode} = {\f2 'constant'},   {\i cval} = {\f2 0},   {\i clip} = {\f2 True},   {\i preserve_range} = {\f2 False},   {\i anti_aliasing} = {\f2 False},   {\i anti_aliasing_sigma} = {\f2 None})}}
\par
{\bkmkstart AAAAAAAAXK}
{\bkmkend AAAAAAAAXK}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid A wrapper for Scikit-Image resize().\par
\par
Scikit-Image generates warnings on every call to resize() if it doesn't\par
receive the right parameters. The right parameters depend on the version\par
of skimage. This solves the problem by using different parameters per\par
version. And it provides a central place to control resizing defaults.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 893            preserve_range={\cf17 False}, anti_aliasing={\cf17 False}, anti_aliasing_sigma={\cf18 None}):\par
894     {\cf22 """A wrapper for Scikit-Image resize().}\par
895 {\cf22 }\par
896 {\cf22     Scikit-Image generates warnings on every call to resize() if it doesn't}\par
897 {\cf22     receive the right parameters. The right parameters depend on the version}\par
898 {\cf22     of skimage. This solves the problem by using different parameters per}\par
899 {\cf22     version. And it provides a central place to control resizing defaults.}\par
900 {\cf22     """}\par
901     {\cf19 if} LooseVersion(skimage.__version__) >= LooseVersion({\cf22 "0.14"}):\par
902         {\cf20 # New in 0.14: anti_aliasing. Default it to False for backward}\par
903         {\cf20 # compatibility with skimage 0.13.}\par
904         {\cf19 return} skimage.transform.resize(\par
905             image, output_shape,\par
906             order=order, mode=mode, cval=cval, clip=clip,\par
907             preserve_range=preserve_range, anti_aliasing=anti_aliasing,\par
908             anti_aliasing_sigma=anti_aliasing_sigma)\par
909     {\cf19 else}:\par
910         {\cf19 return} skimage.transform.resize(\par
911             image, output_shape,\par
912             order=order, mode=mode, cval=cval, clip=clip,\par
913             preserve_range=preserve_range)\par
914 \par
}
{
\ql
Referenced by {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWW" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.expand_mask()}}}
, {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWV" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.minimize_mask()}}}
, and {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAWT" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.resize_image()}}}
.}\par
}
{\xe \v resize_image\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:resize_image}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
resize_image (  {\i image},   {\i min_dim} = {\f2 None},   {\i max_dim} = {\f2 None},   {\i min_scale} = {\f2 None},   {\i mode} = {\f2 "square"})}}
\par
{\bkmkstart AAAAAAAAWT}
{\bkmkend AAAAAAAAWT}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Resizes an image keeping the aspect ratio unchanged.\par
\par
min_dim: if provided, resizes the image such that it's smaller\par
    dimension == min_dim\par
max_dim: if provided, ensures that the image longest side doesn't\par
    exceed this value.\par
min_scale: if provided, ensure that the image is scaled up by at least\par
    this percent even if min_dim doesn't require it.\par
mode: Resizing mode.\par
    none: No resizing. Return the image unchanged.\par
    square: Resize and pad with zeros to get a square image\par
        of size [max_dim, max_dim].\par
    pad64: Pads width and height with zeros to make them multiples of 64.\par
           If min_dim or min_scale are provided, it scales the image up\par
           before padding. max_dim is ignored in this mode.\par
           The multiple of 64 is needed to ensure smooth scaling of feature\par
           maps up and down the 6 levels of the FPN pyramid (2**6=64).\par
    crop: Picks random crops from the image. First, scales the image based\par
          on min_dim and min_scale, then picks a random crop of\par
          size min_dim x min_dim. Can be used in training only.\par
          max_dim is not used in this mode.\par
\par
Returns:\par
image: the resized image\par
window: (y1, x1, y2, x2). If max_dim is provided, padding might\par
    be inserted in the returned image. If so, this window is the\par
    coordinates of the image part of the full image (excluding\par
    the padding). The x2, y2 pixels are not included.\par
scale: The scale factor used to resize the image\par
padding: Padding added to the image [(top, bottom), (left, right), (0, 0)]\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 393 {\cf17 def }resize_image(image, min_dim=None, max_dim=None, min_scale=None, mode="square"):\par
394     {\cf22 """Resizes an image keeping the aspect ratio unchanged.}\par
395 {\cf22 }\par
396 {\cf22     min_dim: if provided, resizes the image such that it's smaller}\par
397 {\cf22         dimension == min_dim}\par
398 {\cf22     max_dim: if provided, ensures that the image longest side doesn't}\par
399 {\cf22         exceed this value.}\par
400 {\cf22     min_scale: if provided, ensure that the image is scaled up by at least}\par
401 {\cf22         this percent even if min_dim doesn't require it.}\par
402 {\cf22     mode: Resizing mode.}\par
403 {\cf22         none: No resizing. Return the image unchanged.}\par
404 {\cf22         square: Resize and pad with zeros to get a square image}\par
405 {\cf22             of size [max_dim, max_dim].}\par
406 {\cf22         pad64: Pads width and height with zeros to make them multiples of 64.}\par
407 {\cf22                If min_dim or min_scale are provided, it scales the image up}\par
408 {\cf22                before padding. max_dim is ignored in this mode.}\par
409 {\cf22                The multiple of 64 is needed to ensure smooth scaling of feature}\par
410 {\cf22                maps up and down the 6 levels of the FPN pyramid (2**6=64).}\par
411 {\cf22         crop: Picks random crops from the image. First, scales the image based}\par
412 {\cf22               on min_dim and min_scale, then picks a random crop of}\par
413 {\cf22               size min_dim x min_dim. Can be used in training only.}\par
414 {\cf22               max_dim is not used in this mode.}\par
415 {\cf22 }\par
416 {\cf22     Returns:}\par
417 {\cf22     image: the resized image}\par
418 {\cf22     window: (y1, x1, y2, x2). If max_dim is provided, padding might}\par
419 {\cf22         be inserted in the returned image. If so, this window is the}\par
420 {\cf22         coordinates of the image part of the full image (excluding}\par
421 {\cf22         the padding). The x2, y2 pixels are not included.}\par
422 {\cf22     scale: The scale factor used to resize the image}\par
423 {\cf22     padding: Padding added to the image [(top, bottom), (left, right), (0, 0)]}\par
424 {\cf22     """}\par
425     {\cf20 # Keep track of image dtype and return results in the same dtype}\par
426     image_dtype = image.dtype\par
427     {\cf20 # Default window (y1, x1, y2, x2) and default scale == 1.}\par
428     h, w = image.shape[:2]\par
429     window = (0, 0, h, w)\par
430     scale = 1\par
431     padding = [(0, 0), (0, 0), (0, 0)]\par
432     crop = {\cf18 None}\par
433 \par
434     {\cf19 if} mode == {\cf22 "none"}:\par
435         {\cf19 return} image, window, scale, padding, crop\par
436 \par
437     {\cf20 # Scale?}\par
438     {\cf19 if} min_dim:\par
439         {\cf20 # Scale up but not down}\par
440         scale = max(1, min_dim / min(h, w))\par
441     {\cf19 if} min_scale {\cf19 and} scale < min_scale:\par
442         scale = min_scale\par
443 \par
444     {\cf20 # Does it exceed max dim?}\par
445     {\cf19 if} max_dim {\cf19 and} mode == {\cf22 "square"}:\par
446         image_max = max(h, w)\par
447         {\cf19 if} round(image_max * scale) > max_dim:\par
448             scale = max_dim / image_max\par
449 \par
450     {\cf20 # Resize image using bilinear interpolation}\par
451     {\cf19 if} scale != 1:\par
452         image = resize(image, (round(h * scale), round(w * scale)),\par
453                        preserve_range={\cf17 True})\par
454 \par
455     {\cf20 # Need padding or cropping?}\par
456     {\cf19 if} mode == {\cf22 "square"}:\par
457         {\cf20 # Get new height and width}\par
458         h, w = image.shape[:2]\par
459         top_pad = (max_dim - h) // 2\par
460         bottom_pad = max_dim - h - top_pad\par
461         left_pad = (max_dim - w) // 2\par
462         right_pad = max_dim - w - left_pad\par
463         padding = [(top_pad, bottom_pad), (left_pad, right_pad), (0, 0)]\par
464         image = np.pad(image, padding, mode={\cf22 'constant'}, constant_values=0)\par
465         window = (top_pad, left_pad, h + top_pad, w + left_pad)\par
466     {\cf19 elif} mode == {\cf22 "pad64"}:\par
467         h, w = image.shape[:2]\par
468         {\cf20 # Both sides must be divisible by 64}\par
469         {\cf17 assert} min_dim % 64 == 0, {\cf22 "Minimum dimension must be a multiple of 64"}\par
470         {\cf20 # Height}\par
471         {\cf19 if} h % 64 > 0:\par
472             max_h = h - (h % 64) + 64\par
473             top_pad = (max_h - h) // 2\par
474             bottom_pad = max_h - h - top_pad\par
475         {\cf19 else}:\par
476             top_pad = bottom_pad = 0\par
477         {\cf20 # Width}\par
478         {\cf19 if} w % 64 > 0:\par
479             max_w = w - (w % 64) + 64\par
480             left_pad = (max_w - w) // 2\par
481             right_pad = max_w - w - left_pad\par
482         {\cf19 else}:\par
483             left_pad = right_pad = 0\par
484         padding = [(top_pad, bottom_pad), (left_pad, right_pad), (0, 0)]\par
485         image = np.pad(image, padding, mode={\cf22 'constant'}, constant_values=0)\par
486         window = (top_pad, left_pad, h + top_pad, w + left_pad)\par
487     {\cf19 elif} mode == {\cf22 "crop"}:\par
488         {\cf20 # Pick a random crop}\par
489         h, w = image.shape[:2]\par
490         y = random.randint(0, (h - min_dim))\par
491         x = random.randint(0, (w - min_dim))\par
492         crop = (y, x, min_dim, min_dim)\par
493         image = image[y:y + min_dim, x:x + min_dim]\par
494         window = (0, 0, min_dim, min_dim)\par
495     {\cf19 else}:\par
496         {\cf19 raise} Exception({\cf22 "Mode \{\} not supported"}.format(mode))\par
497     {\cf19 return} image.astype(image_dtype), window, scale, padding, crop\par
498 \par
499 \par
}
{
\ql
References {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXK" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.resize()}}}
.}\par
}
{\xe \v resize_mask\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:resize_mask}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
resize_mask (  {\i mask},   {\i scale},   {\i padding},   {\i crop} = {\f2 None})}}
\par
{\bkmkstart AAAAAAAAWU}
{\bkmkend AAAAAAAAWU}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Resizes a mask using the given scale and padding.\par
Typically, you get the scale and padding from resize_image() to\par
ensure both, the image and the mask, are resized consistently.\par
\par
scale: mask scaling factor\par
padding: Padding to add to the mask in the form\par
        [(top, bottom), (left, right), (0, 0)]\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 500 {\cf17 def }resize_mask(mask, scale, padding, crop=None):\par
501     {\cf22 """Resizes a mask using the given scale and padding.}\par
502 {\cf22     Typically, you get the scale and padding from resize_image() to}\par
503 {\cf22     ensure both, the image and the mask, are resized consistently.}\par
504 {\cf22 }\par
505 {\cf22     scale: mask scaling factor}\par
506 {\cf22     padding: Padding to add to the mask in the form}\par
507 {\cf22             [(top, bottom), (left, right), (0, 0)]}\par
508 {\cf22     """}\par
509     {\cf20 # Suppress warning from scipy 0.13.0, the output shape of zoom() is}\par
510     {\cf20 # calculated with round() instead of int()}\par
511     {\cf17 with} warnings.catch_warnings():\par
512         warnings.simplefilter({\cf22 "ignore"})\par
513         mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\par
514     {\cf19 if} crop {\cf19 is} {\cf19 not} {\cf18 None}:\par
515         y, x, h, w = crop\par
516         mask = mask[y:y + h, x:x + w]\par
517     {\cf19 else}:\par
518         mask = np.pad(mask, padding, mode={\cf22 'constant'}, constant_values=0)\par
519     {\cf19 return} mask\par
520 \par
521 \par
}
}
{\xe \v trim_zeros\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:trim_zeros}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
trim_zeros (  {\i x})}}
\par
{\bkmkstart AAAAAAAAXB}
{\bkmkend AAAAAAAAXB}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
\par
{
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
Miscellaneous. }}\par
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid It's common to have tensors larger than the available data and\par
pad with zeros. This function removes rows that are all zeros.\par
\par
x: [rows, columns].\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 651 {\cf17 def }trim_zeros(x):\par
652     {\cf22 """It's common to have tensors larger than the available data and}\par
653 {\cf22     pad with zeros. This function removes rows that are all zeros.}\par
654 {\cf22 }\par
655 {\cf22     x: [rows, columns].}\par
656 {\cf22     """}\par
657     {\cf17 assert} len(x.shape) == 2\par
658     {\cf19 return} x[~np.all(x == 0, axis=1)]\par
659 \par
660 \par
}
{
\ql
Referenced by {\field {\*\fldinst { HYPERLINK  \\l "AAAAAAAAXC" }{}}{\fldrslt {\cs37\ul\cf2 PeopleTracker.src.utils.compute_matches()}}}
.}\par
}
{\xe \v unmold_mask\:PeopleTracker.src.utils}
{\xe \v PeopleTracker.src.utils\:unmold_mask}
\pard\plain \s4\sb240\sa60\keepn\widctlpar\adjustright \b\f1\fs20\cgrid {
{\b 
unmold_mask (  {\i mask},   {\i bbox},   {\i image_shape})}}
\par
{\bkmkstart AAAAAAAAWY}
{\bkmkend AAAAAAAAWY}
{
\pard\plain \s61\li360\sa60\sb30\qj\widctlpar\qj\adjustright \fs20\cgrid 
{\s17\sa60\sb30\widctlpar\qj \fs22\cgrid 
{
\par
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid Converts a mask generated by the neural network to a format similar\par
to its original shape.\par
mask: [height, width] of type float. A small, typically 28x28 mask.\par
bbox: [y1, x1, y2, x2]. The box to fit the mask in.\par
\par
Returns a binary mask with the same size as the original image.\par
}
 \par
}{
\pard\plain \s41\li360\widctlpar\adjustright \shading1000\cbpat8 \f2\fs16\cgrid 565 {\cf17 def }unmold_mask(mask, bbox, image_shape):\par
566     {\cf22 """Converts a mask generated by the neural network to a format similar}\par
567 {\cf22     to its original shape.}\par
568 {\cf22     mask: [height, width] of type float. A small, typically 28x28 mask.}\par
569 {\cf22     bbox: [y1, x1, y2, x2]. The box to fit the mask in.}\par
570 {\cf22 }\par
571 {\cf22     Returns a binary mask with the same size as the original image.}\par
572 {\cf22     """}\par
573     threshold = 0.5\par
574     y1, x1, y2, x2 = bbox\par
575     mask = resize(mask, (y2 - y1, x2 - x1))\par
576     mask = np.where(mask >= threshold, 1, 0).astype(np.bool)\par
577 \par
578     {\cf20 # Put the mask in the right location.}\par
579     full_mask = np.zeros(image_shape[:2], dtype=np.bool)\par
580     full_mask[y1:y2, x1:x2] = mask\par
581     {\cf19 return} full_mask\par
582 \par
583 \par
}
}
}